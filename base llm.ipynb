{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef311bef",
   "metadata": {},
   "source": [
    "# Base LLM (LLM runs on cloud (replicate) via API key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73067ce8",
   "metadata": {},
   "source": [
    "## Single Prompt Program "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dbd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r8_1tXV1Jxf2JBIiunu0PrGCEuYgOabv251OjQ0x  (my personal access token of REPLICATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d55643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain tiktoken replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc5fe5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.305\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\n",
      "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langsmith, numexpr, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -jango (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbd832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_1tXV1Jxf2JBIiunu0PrGCEuYgOabv251OjQ0x\"\n",
    "\n",
    "from langchain.llms import Replicate\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "llm = Replicate(\n",
    "    model=\"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5\",\n",
    "    input={\"temperature\": 0.75,\n",
    "           \"max_length\": 500,\n",
    "           \"top_p\": 1},\n",
    ")\n",
    "\n",
    "def use_my_model():\n",
    "    prompt = input()\n",
    "    output = llm(prompt)\n",
    "    \n",
    "    for i in range(1, len(output), 1):\n",
    "        print(output[i] , end = \"\")    \n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c6ee867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a GPU ? How does it differ from a CPU ?\n",
      " GPU, or graphics processing unit, is a specialized type of processor designed specifically for handling the complex mathematical computations required to render 3D graphics and video games. Unlike a CPU, which is a general-purpose processor that can handle a wide range of tasks, a GPU is optimized for a specific set of tasks, such as graphics rendering, machine learning, and cryptocurrency mining.\n",
      "\n",
      "Here are some key differences between a GPU and a CPU:\n",
      "\n",
      "1. Architecture: A GPU is designed with a large number of simple processing units called CUDA cores or stream processors, which are optimized for parallel processing. A CPU, on the other hand, is designed with a smaller number of more complex processing units called cores.\n",
      "2. Memory hierarchy: A GPU has a specialized memory hierarchy that is optimized for fast access to large amounts of data, such as textures and vertex positions. A CPU, on the other hand, has a more general-purpose memory hierarchy that is better suited for handling a wide range of tasks.\n",
      "3. Compute capabilities: A GPU is designed to handle large numbers of floating-point calculations per second, which is essential for rendering 3D graphics and video games. A CPU, on the other hand, is better suited for handling more general-purpose compute tasks, such as running software applications.\n",
      "4. Power consumption: Because a GPU is designed for a specific set of tasks, it can consume more power than a CPU, especially when running at high speeds. However, modern GPUs are also highly power-efficient, and many can be run at low power consumption levels when not in use.\n",
      "5. Programming model: A GPU is typically programmed using specialized APIs such as CUDA or OpenCL, which allow developers to tap into the parallel processing capabilities of the GPU. A CPU, on the other hand, is typically programmed using more general-purpose programming languages such as C++ or Python.\n",
      "In summary, a GPU is a highly specialized processor that is optimized for handling complex mathematical computations required for rendering 3D graphics and video games. It differs from a CPU in terms of architecture, memory hierarchy, compute capabilities, power consumption, and programming model."
     ]
    }
   ],
   "source": [
    "output = use_my_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331d447",
   "metadata": {},
   "source": [
    "## Sequential Prompt Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcedcb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215c6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb227f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60c34f00",
   "metadata": {},
   "source": [
    "### Base LLM (LLM runs on machine's processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e281cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "template = '''Question: {question}\n",
    "Answer: Let's think step by step\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(template = template , \n",
    "                       input_variables = [\"question\"])\n",
    "\n",
    "def load_llm():\n",
    "    llm = CTransformers(\n",
    "    \n",
    "        model = \"llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
    "        model_type = \"llama\",\n",
    "        max_new_tokens = 512,\n",
    "        temperature = 0.5\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm_chain = LLMChain( prompt = prompt , llm = load_llm())\n",
    "\n",
    "question = \"Greet me please!\"\n",
    "\n",
    "print(llm_chain.run(question))\n",
    "\n",
    "llm = load_llm()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c808e533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7547b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5e7688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26241f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079ac2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd285fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTransformers(client=<ctransformers.llm.LLM object at 0x000002908E6A70D0>, model='llama-2-7b-chat.ggmlv3.q8_0.bin', model_type='llama')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa6149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0941f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8451c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f80114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e4fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
